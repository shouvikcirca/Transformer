{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import fasttext as ft\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "\n",
    "d_model = 10\n",
    "new_dim = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feedforward_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(feedforward_Encoder,self).__init__()\n",
    "        self.l1 = nn.Linear(10,40)\n",
    "        self.l2 = nn.Linear(40,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = F.relu(self.l1(x))\n",
    "        y = self.l2(y)\n",
    "        return y\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 10\n",
    "c = 5\n",
    "query_weights = abs(torch.rand((r,c)))\n",
    "key_weights = abs(torch.rand((r,c)))\n",
    "value_weights = abs(torch.rand((r,c)))\n",
    "\n",
    "params = []\n",
    "params = params + list(query_weights) + list(key_weights) + list(value_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "    def __init__(self):\n",
    "        self.d_model = d_model\n",
    "        self.new_dim = new_dim\n",
    "        self.positional_encodings = None\n",
    "        self.first_sublayer_output = None\n",
    "        self.keys = None\n",
    "        self.values = None\n",
    "        \n",
    "\n",
    "\n",
    "    def PositionalEncoding(self,wordVecs):\n",
    "        for pos in range(wordVecs.shape[0]):\n",
    "            for i in range(wordVecs[pos].shape[0]):\n",
    "                if i%2 == 0:\n",
    "                    wordVecs[pos][i] = wordVecs[pos][i] + math.sin(pos/(10000**(2*i/self.d_model)))\n",
    "                else:\n",
    "                    wordVecs[pos][i] = wordVecs[pos][i] + math.cos(pos/(10000**(2*i/self.d_model))) \n",
    "                    \n",
    "        self.positional_encodings = wordVecs\n",
    "        return wordVecs\n",
    "    \n",
    "    \n",
    "    \n",
    "    def qkvs(self,vectorMatrix, new_dim):\n",
    "        return torch.matmul(vectorMatrix, query_weights), torch.matmul(vectorMatrix, key_weights), \\\n",
    "        torch.matmul(vectorMatrix, value_weights) \n",
    "        # Check for transposeness in matrix multiplication\n",
    "    \n",
    "    \n",
    "    def qk_dotproducts(self,queries, keys):\n",
    "        dotproduct_matrix = torch.Tensor([])\n",
    "        for i in queries:\n",
    "            dotproduct_vector = torch.Tensor([])\n",
    "            for j in keys:\n",
    "                dotproduct_vector = torch.cat([dotproduct_vector, torch.dot(i,j).reshape(-1)])\n",
    "            dotproduct_matrix = torch.cat([dotproduct_matrix, dotproduct_vector.reshape(1,-1)])\n",
    "        return dotproduct_matrix\n",
    "    \n",
    "    \n",
    "    def getSoftmaxed_qkdp(self,qk_dotproductmatrix):\n",
    "        sm = nn.Softmax(dim = 0)\n",
    "        sm_matrix = torch.tensor([])\n",
    "        for i in qk_dotproductmatrix:\n",
    "            sm_matrix = torch.cat([sm_matrix, sm(i).reshape(1,-1)])\n",
    "        return sm_matrix\n",
    "    \n",
    "    \n",
    "    def getSoftmaxWeightedValues(self,softmaxed_qkdp, values):\n",
    "        dim2_mat = torch.tensor([])\n",
    "        dim3_mat = torch.tensor([])\n",
    "        outer_loop_range = softmaxed_qkdp.shape[0]\n",
    "        inner_loop_range = values.shape[0]\n",
    "        for i in range(outer_loop_range):\n",
    "            for j in range(inner_loop_range):\n",
    "                dim2_mat = torch.cat([dim2_mat, (softmaxed_qkdp[i][j]*values[j]).reshape(-1)])\n",
    "            dim3_mat = torch.cat([dim3_mat, dim2_mat.reshape(1,values.shape[0],values.shape[1])])\n",
    "            dim2_mat = torch.tensor([]) \n",
    "        return dim3_mat\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getWeightedSum(self,softmax_weighted_values):\n",
    "        next_layer_input = torch.tensor([])\n",
    "        for i in softmax_weighted_values:\n",
    "            transposed_i = i.t()\n",
    "            new_word_representation = torch.tensor([])\n",
    "            for j in transposed_i:\n",
    "                rowsum = j.sum()\n",
    "                new_word_representation = torch.cat([new_word_representation, rowsum.reshape(-1)])\n",
    "            next_layer_input = \\\n",
    "            torch.cat([next_layer_input, new_word_representation.reshape(1,new_word_representation.shape[0])])    \n",
    "        return next_layer_input\n",
    "        \n",
    "    \n",
    "    \n",
    "    def returnRepresentation(self, vectorRepresentations):\n",
    "        pos_encoded = self.PositionalEncoding(vectorRepresentations)\n",
    "        new_dim = self.new_dim\n",
    "        queries, keys, values = self.qkvs(pos_encoded, new_dim)\n",
    "        qk_dotproductmatrix = self.qk_dotproducts(queries, keys)\n",
    "        d_k = keys.shape[1] # to be changed later to square root of 'key' vector dimension\n",
    "        qk_dotproductmatrix/=(d_k**0.5)\n",
    "        softmaxed_qkdp = self.getSoftmaxed_qkdp(qk_dotproductmatrix)\n",
    "        softmax_weighted_values = self.getSoftmaxWeightedValues(softmaxed_qkdp, values)\n",
    "        weightedSum = self.getWeightedSum(softmax_weighted_values)\n",
    "        return weightedSum  \n",
    "    \n",
    "    \n",
    "    def getW0(self):\n",
    "        self.t = torch.randn(self.d_model, self.d_model).float()\n",
    "        return self.t\n",
    "    \n",
    "    \n",
    "    \n",
    "    def multiHeadAttention(self, vectorRepresentations, heads=2):\n",
    "        listOfHeads = []\n",
    "        op = torch.tensor([])\n",
    "        for i in range(heads):\n",
    "            temp = self.returnRepresentation(vectorRepresentations)\n",
    "            listOfHeads.append(temp)\n",
    "    \n",
    "        outputRepresentation = torch.tensor([])\n",
    "        for i in range(listOfHeads[0].shape[0]):\n",
    "            outputRepresentation = torch.cat([listOfHeads[0][i],listOfHeads[1][i]])\n",
    "            op = torch.cat([op, outputRepresentation.reshape(1,outputRepresentation.shape[0])])\n",
    "        \n",
    "        W0 = self.getW0()\n",
    "        projected_attention_vecs = torch.matmul(op, W0) \n",
    "        #Layer Normalisation\n",
    "        layer_norm_one = nn.LayerNorm(projected_attention_vecs.size()[1])\n",
    "        add_and_norm = layer_norm_one(projected_attention_vecs+self.positional_encodings)\n",
    "        ##############   \n",
    "        self.first_sublayer_output = add_and_norm\n",
    "        return add_and_norm\n",
    "    \n",
    "    \n",
    "    def ff_and_addnorm(self, vectorRepresentations):\n",
    "        received_representations = self.multiHeadAttention(vectorRepresentations)\n",
    "        activationlist = []\n",
    "        activations = torch.tensor([])\n",
    "        for i in received_representations:\n",
    "            ffobj = feedforward_Encoder()\n",
    "            activationlist.append(ffobj)\n",
    "            activations = torch.cat([activations, activationlist[-1](i).reshape(1,received_representations.\\\n",
    "                                                                                shape[1])])\n",
    "         \n",
    "        layer_norm_two = nn.LayerNorm(activations.size()[1])\n",
    "        add_and_norm = layer_norm_two(activations + self.first_sublayer_output)\n",
    "        return add_and_norm\n",
    "        \n",
    "         \n",
    "    def forward(self, vectorRepresentations):\n",
    "        return self.ff_and_addnorm(vectorRepresentations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 10\n",
    "c = 5\n",
    "decoder_query_weights = abs(torch.rand((r,c)))\n",
    "decoder_key_weights = abs(torch.rand((r,c)))\n",
    "decoder_value_weights = abs(torch.rand((r,c)))\n",
    "\n",
    "\n",
    "decoder_masked_query_weights = abs(torch.rand((r,c)))\n",
    "decoder_masked_key_weights = abs(torch.rand((r,c)))\n",
    "decoder_masked_value_weights = abs(torch.rand((r,c)))\n",
    "\n",
    "W0 = torch.randn(d_model, d_model).float()\n",
    "W1 = torch.randn(d_model, d_model).float()\n",
    "\n",
    "\n",
    "encoder_keys = torch.randn(5,5)\n",
    "encoder_values = torch.randn(5,5)\n",
    "\n",
    "# params = []\n",
    "# params = params + list(query_weights) + list(key_weights) + list(value_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorRepresentations = None\n",
    "        self.positional_encodings = None\n",
    "        self.d_model = d_model\n",
    "        self.new_dim = new_dim\n",
    "        self.maskedMultiHeadAttentionOutputVectors = None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def PositionalEncoding(self,wordVecs):\n",
    "        for pos in range(wordVecs.shape[0]):\n",
    "            for i in range(wordVecs[pos].shape[0]):\n",
    "                if i%2 == 0:\n",
    "                    wordVecs[pos][i] = wordVecs[pos][i] + math.sin(pos/(10000**(2*i/self.d_model)))\n",
    "                else:\n",
    "                    wordVecs[pos][i] = wordVecs[pos][i] + math.cos(pos/(10000**(2*i/self.d_model))) \n",
    "                    \n",
    "        self.positional_encodings = wordVecs\n",
    "        return wordVecs\n",
    "    \n",
    "    \n",
    "\n",
    "    def qkvs_Attention(self,vectorMatrix):\n",
    "        return torch.matmul(vectorMatrix, decoder_query_weights)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def qkvs_maskedAttention(self,vectorMatrix):\n",
    "        return torch.matmul(vectorMatrix, decoder_masked_query_weights), torch.matmul(vectorMatrix, decoder_masked_key_weights), \\\n",
    "        torch.matmul(vectorMatrix, decoder_masked_value_weights) \n",
    "    \n",
    "    \n",
    "    def maskedMatrix(self,m,ind):\n",
    "        returnMatrix = torch.tensor([]).float()\n",
    "        for i in range(m.shape[0]):\n",
    "            if i<=ind:\n",
    "                returnMatrix = torch.cat([returnMatrix,m[i].unsqueeze(0)])\n",
    "            else:\n",
    "                returnMatrix = torch.cat([returnMatrix,torch.tensor([-float('Inf') for k in range(m.shape[1])]).float().unsqueeze(0)])\n",
    "        \n",
    "        return returnMatrix\n",
    "    \n",
    "    \n",
    "    def dotProductMaskedMatrix(self,l,m2):\n",
    "        returnMatrix = torch.tensor([]).float()\n",
    "        for i in range(m2.shape[0]):\n",
    "            returnMatrix = torch.cat([returnMatrix,torch.dot(l,m2[i]).reshape(-1)])\n",
    "       \n",
    "        \n",
    "        return returnMatrix\n",
    "    \n",
    "    \n",
    "    def qk_dotproducts_maskedAttention(self,queries, keys):\n",
    "        finalMatrix = torch.Tensor([])\n",
    "        for i in range(queries.shape[0]):\n",
    "            b = self.maskedMatrix(queries,i)\n",
    "            c = self.dotProductMaskedMatrix(b[i],b)\n",
    "            finalMatrix = torch.cat([finalMatrix,c.unsqueeze(0)])\n",
    "    \n",
    "        return finalMatrix\n",
    "    \n",
    "    \n",
    "    def qk_dotproducts_Attention(self,queries, keys):\n",
    "        dotproduct_matrix = torch.Tensor([])\n",
    "        for i in queries:\n",
    "            dotproduct_vector = torch.Tensor([])\n",
    "            for j in keys:\n",
    "                dotproduct_vector = torch.cat([dotproduct_vector, torch.dot(i,j).reshape(-1)])\n",
    "            dotproduct_matrix = torch.cat([dotproduct_matrix, dotproduct_vector.unsqueeze(0)])\n",
    "            \n",
    "        return dotproduct_matrix\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    " \n",
    "    \n",
    "     \n",
    "    def getSoftmaxWeightedValues(self,softmaxed_qkdp, values):\n",
    "        dim2_mat = torch.tensor([])\n",
    "        dim3_mat = torch.tensor([])\n",
    "        outer_loop_range = softmaxed_qkdp.shape[0]\n",
    "        inner_loop_range = values.shape[0]\n",
    "        for i in range(outer_loop_range):\n",
    "            for j in range(inner_loop_range):\n",
    "                dim2_mat = torch.cat([dim2_mat, (softmaxed_qkdp[i][j]*values[j]).reshape(-1)])\n",
    "            dim3_mat = torch.cat([dim3_mat, dim2_mat.reshape(1,values.shape[0],values.shape[1])])\n",
    "            dim2_mat = torch.tensor([]) \n",
    "        return dim3_mat\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getWeightedSum(self,softmax_weighted_values):\n",
    "        return softmax_weighted_values.sum(dim=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def returnMaskedRepresentation(self, vectorRepresentations):\n",
    "        pos_encoded = self.PositionalEncoding(vectorRepresentations)\n",
    "        new_dim = self.new_dim\n",
    "        queries, keys, values = self.qkvs_maskedAttention(pos_encoded)\n",
    "        \n",
    "        qk_dotproductmatrix = self.qk_dotproducts_maskedAttention(queries, keys)\n",
    "        \n",
    "        d_k = keys.shape[1] # to be changed later to square root of 'key' vector dimension\n",
    "        qk_dotproductmatrix/=(d_k**0.5)\n",
    "        \n",
    "\n",
    "        \n",
    "        qk_dotproductmatrix[:] = nn.Softmax(dim=1)(qk_dotproductmatrix)\n",
    "    \n",
    "    \n",
    "        softmax_weighted_values = self.getSoftmaxWeightedValues(qk_dotproductmatrix, values)\n",
    "        weightedSum = self.getWeightedSum(softmax_weighted_values)\n",
    "        return weightedSum \n",
    "        \n",
    " \n",
    "    \n",
    "    def maskedMultiHeadAttention_add_norm(self, vectorRepresentations, heads=2):\n",
    "        listOfHeads = []\n",
    "        op = torch.tensor([])\n",
    "        \n",
    "        #Multiple Heads\n",
    "        for i in range(heads):\n",
    "            temp = self.returnMaskedRepresentation(vectorRepresentations)\n",
    "            listOfHeads.append(temp)\n",
    "    \n",
    "        outputRepresentation = torch.tensor([])\n",
    "        for i in range(listOfHeads[0].shape[0]):\n",
    "            outputRepresentation = torch.cat([listOfHeads[0][i],listOfHeads[1][i]])\n",
    "            op = torch.cat([op, outputRepresentation.reshape(1,outputRepresentation.shape[0])])\n",
    "            \n",
    "        \n",
    "    \n",
    "        projected_attention_vecs = torch.matmul(op, W0) \n",
    "        #Layer Normalisation\n",
    "        layer_norm_one = nn.LayerNorm(projected_attention_vecs.size()[1])\n",
    "        add_and_norm_one = layer_norm_one(projected_attention_vecs+self.positional_encodings)\n",
    "        ##############   \n",
    "        self.first_sublayer_output = add_and_norm_one\n",
    "        return add_and_norm_one\n",
    "        \n",
    "     \n",
    "    \n",
    "    def returnRepresentation(self, vectorRepresentations):\n",
    "        inp_vectors = self.maskedMultiHeadAttention_add_norm(vectorRepresentations)\n",
    "        self.maskedMultiHeadAttentionOutputVectors = inp_vectors\n",
    "        \n",
    "\n",
    "        queries = self.qkvs_Attention(inp_vectors)\n",
    "        \n",
    "        keys = torch.matmul(Encoder_output, decoder_query_weights)\n",
    "        values = torch.matmul(Encoder_output, decoder_value_weights)\n",
    "        \n",
    "        qk_dotproductmatrix = self.qk_dotproducts_Attention(queries, keys)\n",
    "        d_k = keys.shape[1] # to be changed later to square root of 'key' vector dimension\n",
    "        qk_dotproductmatrix/=(d_k**0.5) #In paper we divide by sqrt(d_k) that is sqrt(64) = 8\n",
    "        \n",
    "\n",
    "        \n",
    "        softmaxed_qkdp = nn.Softmax(dim = 1)(qk_dotproductmatrix)\n",
    "        \n",
    "        softmax_weighted_values = self.getSoftmaxWeightedValues(softmaxed_qkdp, values)\n",
    "        weightedSum = softmax_weighted_values.sum(dim = 0)\n",
    "        return weightedSum  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def multiHeadAttention_add_norm(self, vectorRepresentations, heads=2):\n",
    "        \n",
    "        listOfHeads = []\n",
    "        op = torch.tensor([])\n",
    "        \n",
    "        #Multiple Heads\n",
    "        for i in range(heads):\n",
    "            temp = self.returnRepresentation(vectorRepresentations)\n",
    "            listOfHeads.append(temp)\n",
    "            \n",
    "   \n",
    "            \n",
    "        outputRepresentation = torch.tensor([])\n",
    "        for i in range(listOfHeads[0].shape[0]):\n",
    "            outputRepresentation = torch.cat([listOfHeads[0][i],listOfHeads[1][i]])\n",
    "            op = torch.cat([op, outputRepresentation.reshape(1,outputRepresentation.shape[0])])\n",
    "        \n",
    "    \n",
    "      \n",
    "        \n",
    "\n",
    "        projected_attention_vecs = torch.matmul(op, W1) \n",
    "      \n",
    "    \n",
    "        #Layer Normalisation\n",
    "        layer_norm_two = nn.LayerNorm(projected_attention_vecs.size()[1])\n",
    "        add_and_norm_two = layer_norm_two(projected_attention_vecs + self.maskedMultiHeadAttentionOutputVectors)\n",
    "        ##############   \n",
    "        self.first_sublayer_output = add_and_norm_two\n",
    "        return add_and_norm_two\n",
    "    \n",
    "    \n",
    "    \n",
    "    def ff_and_addnorm(self, vectorRepresentations):\n",
    "        received_representations = self.multiHeadAttention_add_norm(vectorRepresentations)\n",
    "        \n",
    "        \n",
    "        \n",
    "        activations = torch.tensor([])\n",
    "        ffobj = feedforward_Encoder()\n",
    "        for i in received_representations:\n",
    "            activations = torch.cat([activations, ffobj(i).unsqueeze(0)])\n",
    "         \n",
    "        \n",
    "        \n",
    "        layer_norm_three = nn.LayerNorm(activations.size()[1])\n",
    "        add_and_norm_three = layer_norm_three(activations + received_representations)\n",
    "        return add_and_norm_three\n",
    "    \n",
    "    \n",
    "    def forward(self, vectorRepresentations):\n",
    "        return self.ff_and_addnorm(vectorRepresentations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "\n",
    "germanSens = pickle.load(open(f'subsampledGermanSens.pkl', 'rb'))\n",
    "englishSens = pickle.load(open(f'subsampledEnglishSens.pkl', 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialPadding(germanSens, englishSens):\n",
    "    \n",
    "    germanVecs = [nltk.word_tokenize(sentence) for sentence in germanSens]\n",
    "    englishVecs = [nltk.word_tokenize(sentence) for sentence in englishSens]\n",
    "    \n",
    "    germanVecs = [['sos']+i+['eos'] for i in germanVecs]\n",
    "    englishVecs = [i+['eos'] for i in englishVecs]\n",
    "    \n",
    "    newgermanVecs = []\n",
    "    newenglishVecs = []\n",
    "    \n",
    "    for i in range(100):\n",
    "        if len(germanVecs[i])<=30 and len(englishVecs[i])<=30:\n",
    "            newgermanVecs.append(germanVecs[i])\n",
    "            newenglishVecs.append(englishVecs[i])\n",
    "    \n",
    "    \n",
    "    for i in range(len(newenglishVecs)):\n",
    "        len_en = len(newenglishVecs[i])\n",
    "        len_de = len(newgermanVecs[i])\n",
    "        \n",
    "        \n",
    "        for j in range(32 - len_de):\n",
    "            newgermanVecs[i].append('ppd')\n",
    "        \n",
    "        for j in range(32 - len_en):\n",
    "            newenglishVecs[i].append('ppd')\n",
    "                \n",
    "                \n",
    "    \n",
    "    \n",
    "        \n",
    "            \n",
    "    return newgermanVecs, newenglishVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "germanVecs, englishVecs = initialPadding(germanSens, englishSens)\n",
    "\n",
    "modelGerman = Word2Vec(germanVecs, min_count=1, size=10)\n",
    "modelEnglish = Word2Vec(englishVecs, min_count=1, size=10)\n",
    "\n",
    "# model = Word2Vec(englishVecs+germanVecs, min_count=1, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(germanVecs[0]),len(englishVecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}\n",
    "ind = 0\n",
    "for k in modelGerman.wv.vocab:\n",
    "    word2index[k] = ind\n",
    "    ind+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordVecs(listOfTokens, lang):\n",
    "    wvecs = torch.tensor([]).float()\n",
    "    \n",
    "    for i in listOfTokens:\n",
    "        if lang == 'en':wvecs = torch.cat([wvecs, torch.from_numpy(modelEnglish.wv[i]).unsqueeze(0)])\n",
    "        else: wvecs = torch.cat([wvecs, torch.from_numpy(modelGerman.wv[i]).unsqueeze(0)])\n",
    "        \n",
    "    return wvecs\n",
    "\n",
    "mapToVocab = nn.Sequential(\n",
    "             nn.Linear(10,len(word2index)),\n",
    "             nn.ReLU(),\n",
    "             nn.Softmax(dim = 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Encoder()\n",
    "d = Decoder()\n",
    "\n",
    "translations = torch.Tensor([])\n",
    "for sample in range(10):\n",
    "    english_wordVecs = getWordVecs(englishVecs[sample], 'en')\n",
    "    german_wordVecs = getWordVecs(germanVecs[sample], 'de')\n",
    "    Encoder_output = e.forward(english_wordVecs)\n",
    "    Decoder_output = d.forward(german_wordVecs)\n",
    "    \n",
    "    output = mapToVocab(Decoder_output)\n",
    "    translations = torch.cat([translations, output.unsqueeze(0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show translations\n",
    "\n",
    "predOneHotVector = torch.zeros(len(word2index)).long()\n",
    "ind = 2\n",
    "print(englishSens[ind])\n",
    "print()    \n",
    "mappings = [torch.argmax(i) for i in translations[ind]]\n",
    "for i in mappings:\n",
    "    predOneHotVector[i] = 1\n",
    "    for k in word2index:\n",
    "        if word2index[k] == i:\n",
    "            print(k,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predOneHotVector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target One Hot Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trgOneHot(seqoftokens):\n",
    "    trg = [i for i in seqoftokens if i!='ppd' and i!='sos']\n",
    "    targetOneHot = torch.zeros(len(word2index)).long()\n",
    "    for w in trg:\n",
    "        targetOneHot[word2index[w]] = 1 \n",
    "        \n",
    "    return targetOneHot   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = trgOneHot(germanVecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(target.shape[0]):\n",
    "    for k in word2index:\n",
    "        if target[j] == 1 and word2index[k] == j:\n",
    "            print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_example = getWordVecs(englishVecs[32],'en')\n",
    "each_sentence_length = eng_example.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translated_example = \n",
    "germ = getWordVecs(['sos' for _ in range(eng_example.shape[0])],'de')\n",
    "temp = germ.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(each_sentence_length):\n",
    "    Encoder_output = e.forward(eng_example)\n",
    "    Decoder_output = d.forward(germ)\n",
    "    \n",
    "    temp[i] = Decoder_output[i]\n",
    "    germ = temp.clone()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predOneHotVector_inference = torch.zeros(len(word2index)).long()\n",
    "ind = 32\n",
    "print(englishSens[ind])\n",
    "print()    \n",
    "mappings = [torch.argmax(i) for i in germ]\n",
    "for i in mappings:\n",
    "    predOneHotVector[i] = 1\n",
    "    for k in word2index:\n",
    "        if word2index[k] == i:\n",
    "            print(k,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{k}$: BLEU Score on k-grams only<br>\n",
    "$bp$: Brevity Penalty (Penalizes very short translations)<br>\n",
    "$trans$: Machine Translation sentence<br>\n",
    "$ref$: Reference Sentence<br>\n",
    "\n",
    "Combined BLEU Score<br>\n",
    "$(bp).e^{\\frac{1}{k} \\sum_{n=1}^{k} p_{n}}$<br>\n",
    "\n",
    "$bp$ = \n",
    "$\\begin{bmatrix}\n",
    "1 & if trans.length \\gt ref.length \\\\\n",
    "e^{(1-\\frac{trans.length}{ref.length})} & otherwise \\\\\n",
    "\\end{bmatrix}$<br>\n",
    "\n",
    "More details: https://www.coursera.org/lecture/nlp-sequence-models/bleu-score-optional-kC2HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(trans, ref, n):\n",
    "    transtemp = nltk.word_tokenize(trans)\n",
    "    reftemp = nltk.word_tokenize(ref)\n",
    "    \n",
    "    psums = 0\n",
    "    for i in range(1,n+1):\n",
    "        t = list(ngrams(transtemp,i))\n",
    "        r = list(ngrams(reftemp,i))\n",
    "        \n",
    "        trans_count = {}\n",
    "        ref_count = {}\n",
    "        \n",
    "        for i in t:\n",
    "            trans_count[i]=trans_count[i]+1 if i in trans_count else 1\n",
    "\n",
    "        for i in r:\n",
    "            ref_count[i]=ref_count[i]+1 if i in ref_count else 1\n",
    "\n",
    "                 \n",
    "        count = 0\n",
    "        countref = 0\n",
    "\n",
    "        for i in trans_count:\n",
    "            count+=trans_count[i]\n",
    "            if i in ref_count:\n",
    "                countref+=ref_count[i]\n",
    "                 \n",
    "        psums+=(countref/count)\n",
    "                 \n",
    "     \n",
    "    pexp = np.exp(psums/n)\n",
    "                 \n",
    "    if len(transtemp)>len(reftemp):\n",
    "        bp = 1\n",
    "    else:\n",
    "        bp = np.exp(1-len(transtemp)/len(reftemp))\n",
    "                 \n",
    "    return bp*pexp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = germanSens[0]\n",
    "ref = germanSens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu(trans,ref,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
