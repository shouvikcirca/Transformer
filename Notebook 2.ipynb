{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import fasttext as ft\n",
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 10\n",
    "new_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feedforward_Encoder(nn.Module):\n",
    "    \n",
    "    def ___init__(self):\n",
    "        super(feedforward_Encoder,self).__init__()\n",
    "        self.l1 = nn.Linear(10,40)\n",
    "        self.l2 = nn.Linear(40,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = F.relu(self.l1(x))\n",
    "        y = self.l2(y)\n",
    "        return y\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "    def __init__(self, vectorRepresentations):\n",
    "        self.vectorRepresentations = vectorRepresentations\n",
    "        self.d_model = d_model\n",
    "        self.new_dim = new_dim\n",
    "        self.positional_encodings = None\n",
    "        self.keys = None\n",
    "        self.values = None\n",
    "\n",
    "\n",
    "    def PositionalEncoding(self,wordVecs):\n",
    "        for pos in range(wordVecs.shape[0]):\n",
    "            for i in range(wordVecs[pos].shape[0]):\n",
    "                if i%2 == 0:\n",
    "                    wordVecs[pos][i] = wordVecs[pos][i] + math.sin(pos/(10000**(2*i/self.d_model)))\n",
    "                else:\n",
    "                    wordVecs[pos][i] = wordVecs[pos][i] + math.cos(pos/(10000**(2*i/self.d_model))) \n",
    "                    \n",
    "        self.positional_encodings = wordVecs\n",
    "        return wordVecs\n",
    "\n",
    "\n",
    "    def get_qkv_weights(self,r,c):\n",
    "        query_weights = torch.rand((r,c))\n",
    "        key_weights = torch.rand((r,c))\n",
    "        value_weights = torch.rand((r,c))\n",
    "        self.keys = key_weights\n",
    "        self.values = value_weights\n",
    "        \n",
    "        return query_weights, key_weights, value_weights\n",
    "    \n",
    "    \n",
    "    def get_keys_and_values(self):\n",
    "        return self.keys, self.values\n",
    "    \n",
    "    \n",
    "    \n",
    "    def qkvs(self,vectorMatrix, new_dim):\n",
    "        query_weights, key_weights, value_weights = self.get_qkv_weights(self.d_model,new_dim)\n",
    "        return torch.matmul(vectorMatrix, query_weights), torch.matmul(vectorMatrix, key_weights), \\\n",
    "        torch.matmul(vectorMatrix, value_weights) \n",
    "        # Check for transposeness in matrix multiplication\n",
    "    \n",
    "    \n",
    "    def qk_dotproducts(self,queries, keys):\n",
    "        dotproduct_matrix = torch.Tensor([])\n",
    "        for i in queries:\n",
    "            dotproduct_vector = torch.Tensor([])\n",
    "            for j in keys:\n",
    "                dotproduct_vector = torch.cat([dotproduct_vector, torch.dot(i,j).reshape(-1)])\n",
    "            dotproduct_matrix = torch.cat([dotproduct_matrix, dotproduct_vector.reshape(1,-1)])\n",
    "        return dotproduct_matrix\n",
    "    \n",
    "    \n",
    "    def getSoftmaxed_qkdp(self,qk_dotproductmatrix):\n",
    "        sm = nn.Softmax(dim = 0)\n",
    "        sm_matrix = torch.tensor([])\n",
    "        for i in qk_dotproductmatrix:\n",
    "            sm_matrix = torch.cat([sm_matrix, sm(i).reshape(1,-1)])\n",
    "        return sm_matrix\n",
    "    \n",
    "    \n",
    "    def getSoftmaxWeightedValues(self,softmaxed_qkdp, values):\n",
    "        dim2_mat = torch.tensor([])\n",
    "        dim3_mat = torch.tensor([])\n",
    "        outer_loop_range = softmaxed_qkdp.shape[0]\n",
    "        inner_loop_range = values.shape[0]\n",
    "        for i in range(outer_loop_range):\n",
    "            for j in range(inner_loop_range):\n",
    "                dim2_mat = torch.cat([dim2_mat, (softmaxed_qkdp[i][j]*values[j]).reshape(-1)])\n",
    "            dim3_mat = torch.cat([dim3_mat, dim2_mat.reshape(1,values.shape[0],values.shape[1])])\n",
    "            dim2_mat = torch.tensor([]) \n",
    "        return dim3_mat\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getWeightedSum(self,softmax_weighted_values):\n",
    "        next_layer_input = torch.tensor([])\n",
    "        for i in softmax_weighted_values:\n",
    "            transposed_i = i.t()\n",
    "            new_word_representation = torch.tensor([])\n",
    "            for j in transposed_i:\n",
    "                rowsum = j.sum()\n",
    "                new_word_representation = torch.cat([new_word_representation, rowsum.reshape(-1)])\n",
    "            next_layer_input = \\\n",
    "            torch.cat([next_layer_input, new_word_representation.reshape(1,new_word_representation.shape[0])])    \n",
    "        return next_layer_input\n",
    "        \n",
    "    \n",
    "    \n",
    "    def returnRepresentation(self):\n",
    "        pos_encoded = self.PositionalEncoding(self.vectorRepresentations)\n",
    "        new_dim = self.new_dim\n",
    "        queries, keys, values = self.qkvs(pos_encoded, new_dim)\n",
    "        qk_dotproductmatrix = self.qk_dotproducts(queries, keys)\n",
    "        d_k = keys.shape[1] # to be changed later to square root of 'key' vector dimension\n",
    "        qk_dotproductmatrix/=d_k\n",
    "        softmaxed_qkdp = self.getSoftmaxed_qkdp(qk_dotproductmatrix)\n",
    "        softmax_weighted_values = self.getSoftmaxWeightedValues(softmaxed_qkdp, values)\n",
    "        weightedSum = self.getWeightedSum(softmax_weighted_values)\n",
    "        return weightedSum  \n",
    "    \n",
    "    \n",
    "    def getW0(self):\n",
    "        self.t = torch.randn(self.d_model, self.d_model).float()\n",
    "        return self.t\n",
    "    \n",
    "    \n",
    "    \n",
    "    def multiHeadAttention(self, wordVecs, heads=2):\n",
    "        listOfHeads = []\n",
    "        op = torch.tensor([])\n",
    "        for i in range(heads):\n",
    "            temp = self.returnRepresentation()\n",
    "            listOfHeads.append(temp)\n",
    "    \n",
    "        outputRepresentation = torch.tensor([])\n",
    "        for i in range(listOfHeads[0].shape[0]):\n",
    "            outputRepresentation = torch.cat([listOfHeads[0][i],listOfHeads[1][i]])\n",
    "            op = torch.cat([op, outputRepresentation.reshape(1,outputRepresentation.shape[0])])\n",
    "        \n",
    "        W0 = self.getW0()\n",
    "        projected_attention_vecs = torch.matmul(op, W0) \n",
    "        #Layer Normalisation\n",
    "        layer_norm = nn.LayerNorm(projected_attention_vecs.size()[1])\n",
    "        add_and_norm = layer_norm(projected_attention_vecs+self.positional_encodings)\n",
    "    \n",
    "        return add_and_norm\n",
    "    \n",
    "    \n",
    "    def ff(self):\n",
    "        received_representations = self.multiHeadAttention(self.vectorRepresentations)\n",
    "        ffobj = feedforward_Encoder()\n",
    "        activations = torch.tensor([])\n",
    "        for i in received_representations:\n",
    "            activations = torch.cat([activations, ffobj(i)])\n",
    "            \n",
    "        return activations\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self):\n",
    "        return self.ff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordVectors(sentence):\n",
    "    sentence = sentence.split(' ')\n",
    "    vecs = torch.rand((len(sentence),10))\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordVecs = getWordVectors('Hi there this is nuts')\n",
    "# wordVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    a = Encoder(wordVecs)\n",
    "    wordVecs = a.forward()\n",
    "#     print(wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'feedforward_Encoder' object has no attribute 'l1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-3caa383e83a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordVecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwordVecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-dc6d0fc4979f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-dc6d0fc4979f>\u001b[0m in \u001b[0;36mff\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreceived_representations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mffobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DeepLearning/dl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-ed42da97464a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DeepLearning/dl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'feedforward_Encoder' object has no attribute 'l1'"
     ]
    }
   ],
   "source": [
    "a = Encoder(wordVecs)\n",
    "wordVecs = a.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Encoder.ff of <__main__.Encoder object at 0x7f085d170710>>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
