{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import fasttext as ft\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "d_model = 10\n",
    "new_dim = 5\n",
    "\n",
    "\n",
    "def getWordVectors(sentence):\n",
    "    sentence = sentence.split(' ')\n",
    "    vecs = torch.rand((len(sentence),10))\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feedforward_Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(feedforward_Encoder,self).__init__()\n",
    "        self.l1 = nn.Linear(10,40)\n",
    "        self.l2 = nn.Linear(40,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = F.relu(self.l1(x))\n",
    "        y = self.l2(y)\n",
    "        return y\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "    def __init__(self, vectorRepresentations):\n",
    "        self.vectorRepresentations = vectorRepresentations\n",
    "        self.d_model = d_model\n",
    "        self.new_dim = new_dim\n",
    "        self.positional_encodings = None\n",
    "        self.first_sublayer_output = None\n",
    "        self.keys = None\n",
    "        self.values = None\n",
    "        \n",
    "\n",
    "\n",
    "    def PositionalEncoding(self,wordVecs):\n",
    "        for pos in range(wordVecs.shape[0]):\n",
    "            for i in range(wordVecs[pos].shape[0]):\n",
    "                if i%2 == 0:\n",
    "                    wordVecs[pos][i] = wordVecs[pos][i] + math.sin(pos/(10000**(2*i/self.d_model)))\n",
    "                else:\n",
    "                    wordVecs[pos][i] = wordVecs[pos][i] + math.cos(pos/(10000**(2*i/self.d_model))) \n",
    "                    \n",
    "        self.positional_encodings = wordVecs\n",
    "        return wordVecs\n",
    "\n",
    "\n",
    "    def get_qkv_weights(self,r,c):\n",
    "        query_weights = torch.rand((r,c))\n",
    "        key_weights = torch.rand((r,c))\n",
    "        value_weights = torch.rand((r,c))\n",
    "        self.keys = key_weights\n",
    "        self.values = value_weights\n",
    "        \n",
    "        return query_weights, key_weights, value_weights\n",
    "    \n",
    "    \n",
    "    def get_keys_and_values(self):\n",
    "        return self.keys, self.values\n",
    "    \n",
    "    \n",
    "    \n",
    "    def qkvs(self,vectorMatrix, new_dim):\n",
    "        query_weights, key_weights, value_weights = self.get_qkv_weights(self.d_model,new_dim)\n",
    "        return torch.matmul(vectorMatrix, query_weights), torch.matmul(vectorMatrix, key_weights), \\\n",
    "        torch.matmul(vectorMatrix, value_weights) \n",
    "        # Check for transposeness in matrix multiplication\n",
    "    \n",
    "    \n",
    "    def qk_dotproducts(self,queries, keys):\n",
    "        dotproduct_matrix = torch.Tensor([])\n",
    "        for i in queries:\n",
    "            dotproduct_vector = torch.Tensor([])\n",
    "            for j in keys:\n",
    "                dotproduct_vector = torch.cat([dotproduct_vector, torch.dot(i,j).reshape(-1)])\n",
    "            dotproduct_matrix = torch.cat([dotproduct_matrix, dotproduct_vector.reshape(1,-1)])\n",
    "        return dotproduct_matrix\n",
    "    \n",
    "    \n",
    "    def getSoftmaxed_qkdp(self,qk_dotproductmatrix):\n",
    "        sm = nn.Softmax(dim = 0)\n",
    "        sm_matrix = torch.tensor([])\n",
    "        for i in qk_dotproductmatrix:\n",
    "            sm_matrix = torch.cat([sm_matrix, sm(i).reshape(1,-1)])\n",
    "        return sm_matrix\n",
    "    \n",
    "    \n",
    "    def getSoftmaxWeightedValues(self,softmaxed_qkdp, values):\n",
    "        dim2_mat = torch.tensor([])\n",
    "        dim3_mat = torch.tensor([])\n",
    "        outer_loop_range = softmaxed_qkdp.shape[0]\n",
    "        inner_loop_range = values.shape[0]\n",
    "        for i in range(outer_loop_range):\n",
    "            for j in range(inner_loop_range):\n",
    "                dim2_mat = torch.cat([dim2_mat, (softmaxed_qkdp[i][j]*values[j]).reshape(-1)])\n",
    "            dim3_mat = torch.cat([dim3_mat, dim2_mat.reshape(1,values.shape[0],values.shape[1])])\n",
    "            dim2_mat = torch.tensor([]) \n",
    "        return dim3_mat\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getWeightedSum(self,softmax_weighted_values):\n",
    "        next_layer_input = torch.tensor([])\n",
    "        for i in softmax_weighted_values:\n",
    "            transposed_i = i.t()\n",
    "            new_word_representation = torch.tensor([])\n",
    "            for j in transposed_i:\n",
    "                rowsum = j.sum()\n",
    "                new_word_representation = torch.cat([new_word_representation, rowsum.reshape(-1)])\n",
    "            next_layer_input = \\\n",
    "            torch.cat([next_layer_input, new_word_representation.reshape(1,new_word_representation.shape[0])])    \n",
    "        return next_layer_input\n",
    "        \n",
    "    \n",
    "    \n",
    "    def returnRepresentation(self):\n",
    "        pos_encoded = self.PositionalEncoding(self.vectorRepresentations)\n",
    "        new_dim = self.new_dim\n",
    "        queries, keys, values = self.qkvs(pos_encoded, new_dim)\n",
    "        qk_dotproductmatrix = self.qk_dotproducts(queries, keys)\n",
    "        d_k = keys.shape[1] # to be changed later to square root of 'key' vector dimension\n",
    "        qk_dotproductmatrix/=d_k\n",
    "        softmaxed_qkdp = self.getSoftmaxed_qkdp(qk_dotproductmatrix)\n",
    "        softmax_weighted_values = self.getSoftmaxWeightedValues(softmaxed_qkdp, values)\n",
    "        weightedSum = self.getWeightedSum(softmax_weighted_values)\n",
    "        return weightedSum  \n",
    "    \n",
    "    \n",
    "    def getW0(self):\n",
    "        self.t = torch.randn(self.d_model, self.d_model).float()\n",
    "        return self.t\n",
    "    \n",
    "    \n",
    "    \n",
    "    def multiHeadAttention(self, wordVecs, heads=2):\n",
    "        listOfHeads = []\n",
    "        op = torch.tensor([])\n",
    "        for i in range(heads):\n",
    "            temp = self.returnRepresentation()\n",
    "            listOfHeads.append(temp)\n",
    "    \n",
    "        outputRepresentation = torch.tensor([])\n",
    "        for i in range(listOfHeads[0].shape[0]):\n",
    "            outputRepresentation = torch.cat([listOfHeads[0][i],listOfHeads[1][i]])\n",
    "            op = torch.cat([op, outputRepresentation.reshape(1,outputRepresentation.shape[0])])\n",
    "        \n",
    "        W0 = self.getW0()\n",
    "        projected_attention_vecs = torch.matmul(op, W0) \n",
    "        #Layer Normalisation\n",
    "        layer_norm_one = nn.LayerNorm(projected_attention_vecs.size()[1])\n",
    "        add_and_norm = layer_norm_one(projected_attention_vecs+self.positional_encodings)\n",
    "        ##############   \n",
    "        self.first_sublayer_output = add_and_norm\n",
    "        return add_and_norm\n",
    "    \n",
    "    \n",
    "    def ff_and_addnorm(self):\n",
    "        received_representations = self.multiHeadAttention(self.vectorRepresentations)\n",
    "        ffobj = feedforward_Encoder()\n",
    "        activations = torch.tensor([])\n",
    "        for i in received_representations:\n",
    "            activations = torch.cat([activations, ffobj(i).reshape(1,received_representations.shape[1])])\n",
    "         \n",
    "        layer_norm_two = nn.LayerNorm(activations.size()[1])\n",
    "        add_and_norm = layer_norm_two(activations + self.first_sublayer_output)\n",
    "        return add_and_norm\n",
    "        \n",
    "         \n",
    "    def forward(self):\n",
    "        return self.ff_and_addnorm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_wordVecs = getWordVectors('Hi there this is nuts')\n",
    "# wordVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    encoding_layer = Encoder(english_wordVecs)\n",
    "    english_wordVecs = encoding_layer.forward()\n",
    "\n",
    "    \n",
    "encoder_keys, encoder_values = a.get_keys_and_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder():\n",
    "    \n",
    "    def __init__(self, vectorRepresentations):\n",
    "        self.vectorRepresentations = vectorRepresentations\n",
    "        self.positional_encodings = None\n",
    "        self.d_model = d_model\n",
    "        self.new_dim = new_dim\n",
    "        \n",
    "    def PositionalEncoding(self,wordVecs):\n",
    "        for pos in range(wordVecs.shape[0]):\n",
    "            for i in range(wordVecs[pos].shape[0]):\n",
    "                if i%2 == 0:\n",
    "                    wordVecs[pos][i] = wordVecs[pos][i] + math.sin(pos/(10000**(2*i/self.d_model)))\n",
    "                else:\n",
    "                    wordVecs[pos][i] = wordVecs[pos][i] + math.cos(pos/(10000**(2*i/self.d_model))) \n",
    "                    \n",
    "        self.positional_encodings = wordVecs\n",
    "        return wordVecs\n",
    "    \n",
    "    \n",
    "    def get_qkv_weights(self,r,c):\n",
    "        query_weights = torch.rand((r,c))\n",
    "        key_weights = torch.rand((r,c))\n",
    "        value_weights = torch.rand((r,c))\n",
    "        self.keys = key_weights\n",
    "        self.values = value_weights\n",
    "        return query_weights, key_weights, value_weights\n",
    "    \n",
    "    \n",
    "    def qkvs(self,vectorMatrix, new_dim):\n",
    "        query_weights, key_weights, value_weights = self.get_qkv_weights(self.d_model,new_dim)\n",
    "        return torch.matmul(vectorMatrix, query_weights), torch.matmul(vectorMatrix, key_weights), \\\n",
    "        torch.matmul(vectorMatrix, value_weights) \n",
    "    \n",
    "    \n",
    "    def qk_dotproducts(self,queries, keys):\n",
    "        dotproduct_matrix = torch.Tensor([])\n",
    "        for i in queries:\n",
    "            dotproduct_vector = torch.Tensor([])\n",
    "            for j in keys:\n",
    "                dotproduct_vector = torch.cat([dotproduct_vector, torch.dot(i,j).reshape(-1)])\n",
    "            dotproduct_matrix = torch.cat([dotproduct_matrix, dotproduct_vector.reshape(1,-1)])\n",
    "        return dotproduct_matrix\n",
    "    \n",
    "    \n",
    "    def conditionedSoftmax(self, i):\n",
    "        \n",
    "        temp = torch.tensor([])\n",
    "        softmax_tensor = torch.tensor([])\n",
    "        sm = nn.Softmax(dim = 0)\n",
    "\n",
    "        for element in i:\n",
    "            if element != 0.0:\n",
    "                temp = torch.cat([temp, element.reshape(-1)])\n",
    "        softmax_tensor = sm(temp)\n",
    "        \n",
    "        for j in range(softmax_tensor.shape[0]):\n",
    "            i[j] = softmax_tensor[j]\n",
    "            \n",
    "#         print(i)\n",
    "    \n",
    "        return i\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getSoftmaxed_qkdp(self,qk_dotproductmatrix):\n",
    "        sm_matrix = torch.tensor([])\n",
    "        for i in qk_dotproductmatrix:\n",
    "            sm_matrix = torch.cat([sm_matrix, self.conditionedSoftmax(i).reshape(1,-1)])\n",
    "        return sm_matrix\n",
    "    \n",
    "     \n",
    "    def getSoftmaxWeightedValues(self,softmaxed_qkdp, values):\n",
    "        dim2_mat = torch.tensor([])\n",
    "        dim3_mat = torch.tensor([])\n",
    "        outer_loop_range = softmaxed_qkdp.shape[0]\n",
    "        inner_loop_range = values.shape[0]\n",
    "        for i in range(outer_loop_range):\n",
    "            for j in range(inner_loop_range):\n",
    "                dim2_mat = torch.cat([dim2_mat, (softmaxed_qkdp[i][j]*values[j]).reshape(-1)])\n",
    "            dim3_mat = torch.cat([dim3_mat, dim2_mat.reshape(1,values.shape[0],values.shape[1])])\n",
    "            dim2_mat = torch.tensor([]) \n",
    "        return dim3_mat\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getWeightedSum(self,softmax_weighted_values):\n",
    "        next_layer_input = torch.tensor([])\n",
    "        for i in softmax_weighted_values:\n",
    "            transposed_i = i.t()\n",
    "            new_word_representation = torch.tensor([])\n",
    "            for j in transposed_i:\n",
    "                rowsum = j.sum()\n",
    "                new_word_representation = torch.cat([new_word_representation, rowsum.reshape(-1)])\n",
    "            next_layer_input = \\\n",
    "            torch.cat([next_layer_input, new_word_representation.reshape(1,new_word_representation.shape[0])])    \n",
    "        return next_layer_input\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def returnRepresentation(self):\n",
    "        pos_encoded = self.PositionalEncoding(self.vectorRepresentations)\n",
    "        new_dim = self.new_dim\n",
    "        queries, keys, values = self.qkvs(pos_encoded, new_dim)\n",
    "        qk_dotproductmatrix = self.qk_dotproducts(queries, keys)\n",
    "        \n",
    "        \n",
    "        #Creating mask matrix\n",
    "        maskmatrix = [[0.0 for i in range(qk_dotproductmatrix.shape[1])]for j\\\n",
    "                      in range(qk_dotproductmatrix.shape[0])]\n",
    "        for i in range(len(maskmatrix)):\n",
    "            for j in range(i+1):\n",
    "                maskmatrix[i][j] = 1\n",
    "        maskmatrix = torch.tensor(maskmatrix).float()\n",
    "        #######################\n",
    "        \n",
    "        \n",
    "        d_k = keys.shape[1] # to be changed later to square root of 'key' vector dimension\n",
    "        qk_dotproductmatrix/=d_k\n",
    "        qk_dotproductmatrix = qk_dotproductmatrix * maskmatrix\n",
    "#         return qk_dotproductmatrix\n",
    "        softmaxed_qkdp = self.getSoftmaxed_qkdp(qk_dotproductmatrix)\n",
    "#         return softmaxed_qkdp    \n",
    "        softmax_weighted_values = self.getSoftmaxWeightedValues(softmaxed_qkdp, values)\n",
    "        print(softmax_weighted_values)\n",
    "        weightedSum = self.getWeightedSum(softmax_weighted_values)\n",
    "        return weightedSum \n",
    "        \n",
    "     \n",
    "    def getW0(self):\n",
    "        self.t = torch.randn(self.d_model, self.d_model).float()\n",
    "        return self.t\n",
    "    \n",
    "    \n",
    "    def maskedMultiHeadAttention_add_norm(self, wordVecs, heads=2):\n",
    "        listOfHeads = []\n",
    "        op = torch.tensor([])\n",
    "        for i in range(heads):\n",
    "            temp = self.returnRepresentation()\n",
    "            listOfHeads.append(temp)\n",
    "    \n",
    "        outputRepresentation = torch.tensor([])\n",
    "        for i in range(listOfHeads[0].shape[0]):\n",
    "            outputRepresentation = torch.cat([listOfHeads[0][i],listOfHeads[1][i]])\n",
    "            op = torch.cat([op, outputRepresentation.reshape(1,outputRepresentation.shape[0])])\n",
    "        \n",
    "        W0 = self.getW0()\n",
    "        projected_attention_vecs = torch.matmul(op, W0) \n",
    "        #Layer Normalisation\n",
    "        layer_norm_one = nn.LayerNorm(projected_attention_vecs.size()[1])\n",
    "        add_and_norm_one = layer_norm_one(projected_attention_vecs+self.positional_encodings)\n",
    "        ##############   \n",
    "        self.first_sublayer_output = add_and_norm_one\n",
    "        return add_and_norm_one\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_wordVecs = getWordVectors('Dans la vallée de la mort')\n",
    "# french_wordVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[4.0955e+00, 5.4431e+00, 6.1252e+00, 2.4585e+00, 4.6336e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[3.0736e+00, 4.0850e+00, 4.5969e+00, 1.8451e+00, 3.4775e+00],\n",
      "         [1.0820e+00, 1.4249e+00, 1.5252e+00, 6.6912e-01, 1.0588e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.9889e-01, 3.9724e-01, 4.4702e-01, 1.7943e-01, 3.3817e-01],\n",
      "         [8.5225e-02, 1.1224e-01, 1.2014e-01, 5.2704e-02, 8.3400e-02],\n",
      "         [4.8259e+00, 6.1555e+00, 6.5570e+00, 3.3183e+00, 4.4902e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[8.9664e-03, 1.1917e-02, 1.3410e-02, 5.3825e-03, 1.0145e-02],\n",
      "         [2.3558e-03, 3.1025e-03, 3.3209e-03, 1.4569e-03, 2.3054e-03],\n",
      "         [2.1402e-01, 2.7298e-01, 2.9078e-01, 1.4716e-01, 1.9913e-01],\n",
      "         [4.6663e+00, 6.6532e+00, 7.4384e+00, 2.8049e+00, 5.2395e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[3.8035e-02, 5.0550e-02, 5.6885e-02, 2.2833e-02, 4.3033e-02],\n",
      "         [1.3746e-02, 1.8103e-02, 1.9377e-02, 8.5006e-03, 1.3451e-02],\n",
      "         [5.1707e-01, 6.5952e-01, 7.0254e-01, 3.5554e-01, 4.8110e-01],\n",
      "         [4.3348e+00, 6.1807e+00, 6.9100e+00, 2.6057e+00, 4.8673e+00],\n",
      "         [4.1903e-03, 6.5903e-03, 8.2976e-03, 2.9071e-03, 5.1200e-03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.2330e-02, 2.9678e-02, 3.3397e-02, 1.3405e-02, 2.5264e-02],\n",
      "         [7.1318e-03, 9.3923e-03, 1.0053e-02, 4.4104e-03, 6.9791e-03],\n",
      "         [3.7093e-01, 4.7312e-01, 5.0398e-01, 2.5505e-01, 3.4513e-01],\n",
      "         [4.4797e+00, 6.3871e+00, 7.1409e+00, 2.6927e+00, 5.0299e+00],\n",
      "         [1.9499e-03, 3.0666e-03, 3.8611e-03, 1.3528e-03, 2.3825e-03],\n",
      "         [1.6522e-02, 2.0931e-02, 2.4332e-02, 1.0362e-02, 1.7980e-02]]])\n",
      "tensor([[[7.5346e+00, 6.9392e+00, 8.7071e+00, 7.6520e+00, 7.4249e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[2.2443e-01, 2.0670e-01, 2.5936e-01, 2.2793e-01, 2.2117e-01],\n",
      "         [7.8586e+00, 7.4238e+00, 9.6433e+00, 8.5596e+00, 7.8381e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[5.1607e-05, 4.7528e-05, 5.9637e-05, 5.2411e-05, 5.0855e-05],\n",
      "         [2.7228e-03, 2.5721e-03, 3.3411e-03, 2.9657e-03, 2.7157e-03],\n",
      "         [9.2022e+00, 8.7264e+00, 1.0759e+01, 9.6540e+00, 9.1243e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[5.0980e-05, 4.6951e-05, 5.8912e-05, 5.1774e-05, 5.0237e-05],\n",
      "         [2.3627e-03, 2.2319e-03, 2.8992e-03, 2.5734e-03, 2.3565e-03],\n",
      "         [5.6429e+00, 5.3511e+00, 6.5978e+00, 5.9199e+00, 5.5951e+00],\n",
      "         [3.1259e+00, 2.9470e+00, 3.8499e+00, 3.4112e+00, 3.1555e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[5.0920e-04, 4.6896e-04, 5.8844e-04, 5.1714e-04, 5.0179e-04],\n",
      "         [1.0861e-02, 1.0260e-02, 1.3328e-02, 1.1830e-02, 1.0833e-02],\n",
      "         [5.5730e+00, 5.2848e+00, 6.5161e+00, 5.8466e+00, 5.5258e+00],\n",
      "         [3.1783e+00, 2.9964e+00, 3.9145e+00, 3.4684e+00, 3.2084e+00],\n",
      "         [7.7333e-07, 6.4044e-07, 8.3238e-07, 7.3723e-07, 6.7389e-07],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[5.1708e-04, 4.7622e-04, 5.9754e-04, 5.2514e-04, 5.0955e-04],\n",
      "         [1.1874e-02, 1.1217e-02, 1.4570e-02, 1.2933e-02, 1.1843e-02],\n",
      "         [5.2860e+00, 5.0127e+00, 6.1805e+00, 5.5455e+00, 5.2413e+00],\n",
      "         [3.4292e+00, 3.2330e+00, 4.2236e+00, 3.7423e+00, 3.4618e+00],\n",
      "         [8.3389e-07, 6.9059e-07, 8.9756e-07, 7.9496e-07, 7.2666e-07],\n",
      "         [2.1991e-05, 1.9587e-05, 2.6476e-05, 2.6321e-05, 2.2697e-05]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8837, -1.5631,  0.3750, -0.0596,  0.4754,  2.3426,  0.3189, -0.0892,\n",
       "         -0.0175, -0.8988],\n",
       "        [-0.8471, -1.4398,  0.2267, -0.2460,  0.5746,  2.3508,  0.3408, -0.1208,\n",
       "          0.1962, -1.0353],\n",
       "        [-0.7381, -1.5955,  0.4828, -0.2323,  0.4887,  2.2831,  0.3011, -0.1163,\n",
       "          0.1488, -1.0222],\n",
       "        [-0.7959, -1.5796,  0.3865, -0.1677,  0.3478,  2.4010,  0.2708, -0.1987,\n",
       "          0.1551, -0.8192],\n",
       "        [-0.8681, -1.5336,  0.4178, -0.1895,  0.3109,  2.3930,  0.3527, -0.1811,\n",
       "          0.1271, -0.8292],\n",
       "        [-0.8732, -1.5923,  0.4085, -0.1370,  0.3352,  2.3639,  0.3352, -0.2284,\n",
       "          0.1761, -0.7879]], grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Decoder(french_wordVecs)\n",
    "a.maskedMultiHeadAttention_add_norm(french_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
